<!--
Google IO 2012/2013 HTML5 Slide Template

Authors: Eric Bidelman <ebidel@gmail.com>
         Luke Mahé <lukem@google.com>

URL: https://code.google.com/p/io-2012-slides
-->

<!DOCTYPE html>
<html>
<head>
  <title>Media APIs</title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
  <!--This one seems to work all the time, but really small on ipad-->
  <!--<meta name="viewport" content="initial-scale=0.4">-->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <link rel="stylesheet" media="all" href="theme/css/default.css">
  <link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css">
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="js/slides" src="js/require-1.0.8.min.js"></script>
</head>
<body style="opacity: 0">

<slides class="layout-widescreen">

<slide class="logoslide nobackground">
  <article class="flexbox vcenter">
    <div style='margin: 0 0 2em 0'><img src="images/google_developers_logo.png" alt="Google developers logo"></div>
<!--     <div>Move forward and back with the arrow keys</div>
 -->  </article>
</slide>

<slide class="title-slide segue nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
  <hgroup class="auto-fadein">
    <h1 style="width: 70%" data-config-title><!-- populated from slide_config.json --></h1>
    <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
    <p data-config-presenter><!-- populated from slide_config.json --></p>
<!--     <p><a href="http://twitter.com/sw12" title="Sam Dutton on Twitter">@sw12</a></p>
 -->  </hgroup>
  <aside class="note"><p>I'm going to talk about media APIs for the modern web: audio, video and realtime communication.</p></aside>
</slide>

<!-- <slide class="nobackground">
  <hgroup>
    <h2>Watch this presentation on YouTube</h2>
  </hgroup>
  <article>
    <iframe  width="730" style="width: 730px;" src="http://www.youtube.com/embed/xxxxxx"></iframe>
  </article>
</slide> -->

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class='big'><a href="http://mediaapis.appspot.com" title="These slides online">mediaapis.appspot.com</a></div>
    </article>
    <aside class="note">
      <p>Before I get going - this deck is live on the web, so you can follow along or refer to it later.</p>
    </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big">Where is the web?</div>
    </article>
    <aside class="note">
      <p>I've noticed two particular trends in the web over the last year.</p>
      <p>The first is obvious.</p>
    </aside>
</slide>

<slide class="nobackground">
    <img alt="Samsung Chromebook series 5" src="images/chromebook.jpg" style="position: relative; top: 100px; left: 157px;">
  <aside class="note">
    <p>A Chromebook with a SIM card?</p>
  </aside>
</slide>

<slide class="nobackground">
    <img alt="Hand holding Kindle DX graphite" src="images/kindle.png" style="position: relative; left: -61px; top: 85px;">
  <aside class="note">
    <p>A Kindle?</p>
  </aside>
</slide>

<slide style="background-image: url(images/sonyVaioTap20.jpg)">
  <aside class="note">
    <p>A 20-inch touch screen?</p>
  </aside>
</slide>

<slide style="background-image: url(images/googleSelfDrivingCar.jpg)">
  <aside class="note">
    <p>My new car? I wish</p>
  </aside>
</slide>


<slide style="background-image: url(images/glass.jpg)">
  <aside class="note">
    <p>My new glasses?</p>
  </aside>
</slide>

<slide style="background-image: url(images/brinMeme.jpg)">
  <aside class="note">
    <p>These are all platforms for web apps.</p>
  </aside>
</slide>

<slide class="nobackground">
  <article class="fill vcenter flexbox">
    <div class="quiteBig">All these devices have a browser.</div>
  </article>
  <aside class="note">
    <p>These are all platforms for web apps.</p>
  </aside>
</slide>

<slide class="fill nobackground" style="background-image: url(images/mobileVDesktop.png)">
  <aside class="note">
    <p>What we do know is that mobile web use is outstripping desktop worldwide.</p>
    <p>In a number of countries mobile has already overtaken desktop.</p>
 </aside>
 <footer class="source">Source: <a href="http://www.morganstanley.com/institutional/techresearch/pdfs/Internet_Trends_041210.pdf">Morgan Stanley Research</a></footer>
</slide>

<slide class="fill nobackground">
  <hgroup>
    <h2>Fastest growing iOS and Android markets</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img alt="Fastest growing iOS and Android markets" src="images/mobileMarkets.png" />
    <footer class="source">Source: <a href="http://blog.flurry.com/bid/88867/iOS-and-Android-Adoption-Explodes-Internationally">Flurry</a>, 27 August 2012</footer>
  </article>
  <aside class="note">
    <p>Massive increase in PhoneGap usage in BRIC countries – Joe McCann at PhoneGap day in 2012.</p>
    <p>Emerging markets where computer equals smartphone.</p>
    <p>MIST is next.</p>
 </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big">What is the web?</div>
    </article>
    <aside class="note">
      <p>So we're seeing a shift in the way people experience the web.</p>
      <p>In particular, the rise and rise of phones, tablets and whatever follows.</p>
      <p>The commoditisation of computing: more mobile phones in the world than pencils or toothbrushes.</p>
      <p>Recently heard an ex-Nokia analyst say 'Enterprise sales are now just noise.'</p>
      <p>It's very like what happened with desktop computers in the 80s and 90s.</p>
      <p>For better or worse, these are devices more oriented to consumption than interaction.</p>
      <p>We're also seeing behaviour shift: we're using mobile on wifi, using mobile devices while watching television -- 25% of TV viewing, according to a recent UK government study.</p>
      <p>And with that we're seeing a second trend on the Web that is perhaps a little less obvious.</p>
      <p>That's the rise and rise of media.</p>
    </aside>
</slide>

<slide class="nobackground">
  <article  class="fill flexbox vcenter">
    <p>Video will be 80 to 90 percent of global consumer traffic by 2017.</p>
  </article>
  <aside class="note">
    <p>We're coming to expect seamless audio, video and realtime communication from apps, games and sites - on a range of devices.</p>
    <p>Every second, nearly a million minutes of video content will cross the network in 2017.</p>
    <p>The sum of all forms of video (TV, video on demand [VoD], Internet, and P2P) will be in the range of 80 to 90 percent of global consumer traffic by 2017.</p>
    <p>It's not that we're all going to build the next YouTube, but we can till make the most of a host of new technologies.</p>
  </aside>
  <footer class="source">Source: <a href="http://goo.gl/RfB73h" title="Cisco networking forecast">Cisco Visual Networking Index: Forecast and Methodology, 2012–2017</a></footer>
</slide>

<slide class="fill nobackground" style="background-image: url(images/evolution.png)">
  <aside class="note">
    <p>I was looking back at presentations last year</p>
    <p>...and I'm struck by how much the mobile web has changed in that time.</p>
    <p>It just seems like the norm now for mobile web developers like you to use APIs and frameworks</p>
    <p>...that really push the limits of what you can do in the mobile browser.</p>
    <p>And the availability of media APIs and better connectivity is pushing the limits as well.</p>
 </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>WebRTC</h2>
    <h3>Real-time communication built into the browser</h3>
  </hgroup>
  <aside class="note">
    <p>Probably the most ambitious web project in recent years is WebRTC.</p>
  </aside>
</slide>

<slide class="segue dark quote nobackground">
  <aside class="gdbar right bottom"><img src="images/google_developers_icon_128.png"></aside>
  <article class="flexbox vleft auto-fadein">
    <q>WebRTC is a new front in the long war for an open and unencumbered web</q>
    <div class="author">
      Brendan Eich<br>
      &ndash; Mozilla CTO and inventor of JavaScript
    </div>
  </article>
  <aside class="note">
    <p>WebRTC is a collaboration to build real time communication into web browsers.</p>
    <p>It's really a response to the demand for realtime communication features in the open web - without plugins or proprietary codecs, free for users and free for developers.</p>
    <p>This has been a big missing feature in the web platform.</p>
  </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class='big'><a href="https://apprtc.appspot.com/">Peer to peer</a></div>
    </article>
    <aside class="note">
      <p>And right up front, I want to be clear that WebRTC is about peer-to-peer communications.</p>
    </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class='big'><img src="images/no.png" alt="RTC via a server" style='max-width: 100%' /></div>
    </article>
    <aside class="note">
      <p>In the past, a lot of RTC was based on a server managing all communications, running all communications through that server.</p>
      <p>It's inefficient and expensive to run a service to relay media.</p>
    </aside>
</slide>


<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class='big'><img src="images/yes.png" alt="RTC peer to peer" style='max-width: 100%' /></div>
    </article>
    <aside class="note">
      <p>So WebRTC is peer to peer - with a nice friendly fluffy cloud right in the middle.</p>
      <p>As we'll find out, it's not quite that simple, but keep this image in mind.</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>Shopping list</h2>
  </hgroup>
  <article>
    <ul>
      <li>IETF communication protocols: <a href="http://tools.ietf.org/html/draft-ietf-rtcweb-overview" title="IETF: Overview: Real Time Protocols for Brower-based Applications">RTCWEB</a>, <a href="http://tools.ietf.org/html/draft-ietf-rtcweb-jsep-00" title="IETF draft proposal">JSEP</a>...</li>
      <li>W3C API standards: <a href="http://www.w3.org/TR/webrtc/" title="W3C WebRTC draft spec">WebRTC</a>, <a href="http://www.w3.org/TR/mediacapture-streams/" title="W3C Media Capture and Streams draft spec">Media Capture and Streams</a>... </li>
      <li>Media and communication stack: <a href="http://www.webrtc.org/reference/webrtc-internals" title="webrtc.org WebRTC Internals: libjingle components reused by WebRTC">libjingle</a>, <a href="http://www.webmproject.org/tools/" title="WebM and VP8 tools">VP8</a>, <a href="http://www.opus-codec.org/" title="Opus Codec home page">Opus</a>...</li>
    </ul>
  </article>
  <aside class="note">
    <p>When I say WebRTC, I want to be clear that WebRTC is actually a collective solution built from a wide litany of various pieces coming together - the base RTCWeb and session protocols from the IETF, WebRTC and Media Capture and Streams from the W3C, the libjingle library for doing XMPP-based peer-to-peer management, and the VP8 video and Opus audio codecs.</p>
    <p>With all of these required pieces, this may seem... fragile.  Like, it must only be implemented on a particular version of Chrome, on one OS, with particular hardware.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>WebRTC across platforms</h2>
  </hgroup>
  <article style="height: 100%; position: relative">
    <ul class="tight" xstyle='margin: 0 1em 0 0'>
      <li><a href="http://apprtc.appspot.com">Chrome and Chrome for Android</a></li>
      <li>Firefox and Firefox for Android</li>
      <li>Opera</li>
      <li>Native <a href="https://code.google.com/p/libjingle/source/browse/trunk/talk/app/webrtc/java/src/org/webrtc/PeerConnection.java">Java</a> and Objective-C bindings</li>
    </ul>
    <img src="images/android.jpg" alt="Firefox/Chrome interoperability" style="position: absolute; right: 2em; top: -82px; width: 320px" />
    <img src="images/firefoxChrome.jpg" alt="Firefox/Chrome interoperability" style="position: absolute; bottom: 5em; width: 45%;" />
  </article>
  <aside class="note">
    <p>Actually, that's not true at all.  Chrome, Firefox and Opera all implement WebRTC; in fact, Chrome and Firefox implement WebRTC on Android, too!  Let's take a look; I'm going to load up our webRTC chat demo, and now I'll go to the same site on my mobile... Wave to yourselves!</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Qt moving to Chromium</h2>
  </hgroup>
  <article>
    <ul>
      <li>Framework for cross-platform/device native and embedded apps</li>
      <li>Qt WebKit => Qt WebEngine</li>
      <li>Multimedia and new HTML5 features such as WebRTC working out-of the-box</li>
    </ul>
  </article>
  <aside class="note">
    <p>The Qt framework (for building cross-platform/device native and embedded apps) is moving from Qt WebKit to Qt WebEngine, based on Chromium, so they will be getting WebRTC support too!</p>
    <p>Putting all of these implementations together, this means...</p>
  </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
       <div class="big" style="margin: 0 0 0.3em 0;"><b>1,000,000,000+</b></div>
       <div>WebRTC endpoints</div>
  </article>
  <aside class="note">
  <p>...we have over one billion WebRTC-enabled users today, which gives some idea of the size of this opportunity. In order to grow the ecosystem further, we're also providing official, supported native versions of WebRTC for Android, and iOS.</p>
  </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <div><a href="http://blog.vline.com/post/61581986806/live-tv-interview-powered-by-vline-customer-in-quality" title="vLine blog post" style="border-bottom: none;"><img src="images/skyLarge.jpg" alt="Sky TV interview done via WebRTC" style="width: 100%;" /></a></div>
  </article>
  <aside class="note">
  <p>Back in August vLine facilitated the first live TV interview done via WebRTC on SkyNews.</p>
  </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class='big'><img src="images/obTrucks.jpg" alt="Outdoor broadcast truck" style='width: 100%' /></div>
      <footer class="source" style='position: absolute; bottom: 23px; left: 150px'><a href="https://en.wikipedia.org/wiki/File:BBC_HD_SNG.jpg" title="OB trucks">en.wikipedia.org/wiki/File:BBC_HD_SNG.jpg</a></footer>
    </article>
    <aside class="note">
      <p>To put this in context - typically live TV interview setups look like this.</p>
    </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <img src="images/skyKit.jpg" alt="Webcam and Yeti mic used for Sky interview" style="width: 100%;" />
  </article>
  <aside class="note">
  <p>By contrast, the rig used to do that SkyNews interview looked like this - like a standard video podcasting rig.  WebRTC is about democratizing peer-to-peer realtime audio and video communications.</p>
  </aside>
</slide>


<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>What do we need for RTC?</h2>
    <h3></h3>
  </hgroup>
  <aside class="note">
    <p>So that's the vision for WebRTC. Now let's dig into how WebRTC works.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Four main tasks</h2>
  </hgroup>
    <article>
  <ul>
    <li>Acquiring audio and video</li>
    <li>Establishing a connection between peers</li>
    <li>Communicating audio and video</li>
    <li>Communicating arbitrary data</li>
  </ul>
    </article>
    <aside class="note">
    <p></p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>Three main JavaScript APIs</h2>
  </hgroup>
  <article>
  <ul>
    <li>MediaStreams (aka getUserMedia)</li>
    <li>RTCPeerConnection</li>
    <li>RTCDataChannel</li>
  </ul>
  </article>
  <aside class="note">
  </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>MediaStreams</h2>
    <h3>Acquiring audio and video</h3>
  </hgroup>
  <aside class="note">
    <p>So let's dive in to how we acquire and access local audio and video streams.</p>
    <p></p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>MediaStream</h2>
  </hgroup>
  <article>
    <ul>
      <li>Represents a stream of synchronised media</li>
      <li>Can contain multiple audio and/or video MediaStreamTracks</li>
      <li>Obtain a MediaStream with <code>navigator.getUserMedia()</code></li>
    </ul>
  </article>
  <aside class="note">
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>gUM</h2>
    <h3>It's pretty simple.</h3>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
var constraints = {video: true};

function successCallback(stream) {
  var video = document.querySelector("video");
  video.src = window.URL.createObjectURL(stream);
}

function errorCallback(error) {
  console.log("navigator.getUserMedia error: ", error);
}

<b>navigator.getUserMedia(constraints, successCallback, errorCallback);</b>
</pre>
  </article>
</slide>


<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <div class="big"><a href="http://www.simpl.info/gum" title="Simple getUserMedia demo">simpl.info/gum</a></div>
  </article>
  <aside class="note">
    <p>You can also do other things with that video stream - most notably, you can assign it to a video SRC attribute, and display it live!</p>
    <p>I want to briefly talk about security of this access to the camera...</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>gUM permissions</h2>
  </hgroup>
  <article>
    <ul>
      <li>HTTPS only prompts once!</li>
      <li>Chrome apps: <code>audioCapture</code> and <code>videoCapture</code> permissions</li>
      <li>UI settings can be changed afterwards.</li>
      <li>Chrome flag: <code>--use-fake-ui-for-media-stream</code></li>
    </ul>
  </article>
  <aside class="note">
   <p>If you run with HTTPS, or from an app, permission will only be asked for once.</p>
    <p>Likewise with Chrome apps that ask for "audioCapture" and"videoCapture" permissions. Permission is only requested on installation. gUM isn't available for Chrome extensions at this point, though I believe some have been whitelisted.</p>
    <p>To change cameras/settings in Chrome click to the right of the URL bar</p>
  </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class='big'><img src="images/file.png" alt="Don't use file:// URLs" style='max-width: 100%' /></div>
    </article>
    <aside class="note">
      <p>A word of warning: you must run getUserMedia() from a server.</p>
      <p>Otherwise you'll get a rather baffling PERMISSION_DENIED error.</p>
      <p>There are efforts underway to provide better error messages.</p>
      <p>file:// URLs are prohibited for lots of Chrome APIs to avoid security problems</p>
    </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div style="margin: 0 0 1em 0; font-weight: bold">gUM + Canvas</div>
      <div><a href="http://idevelop.github.com/ascii-camera/" title="getUserMedia video rendered as ASCII art">idevelop.github.com/ascii-camera</a></div>
<!--      <div>(<a href="http://idevelop.ro/ascii-camera/">alternate link</a>)</div>-->
    </article>
    <aside class="note">
    <p>gUM gets interesting when plugged into other APIs.</p>
    <p>This page is frame-grabbing images from the gUM video, and then analysing each pixel and turning it into ASCII.</p>
    </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://lli.web.fh-koeln.de/mocowe" title="getUserMedia used to control a slide deck">lli.web.fh-koeln.de/mocowe</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<slide>
  <hgroup>
  </hgroup>
    <article class="fill flexbox vcenter">
      <div style="margin: 0 0 1em 0; font-weight: bold">Select resolution</div>
      <div><a href="https://simpl.info/getusermedia/constraints/" title="getUserMedia constraints demo">simpl.info/getusermedia/constraints</a></div>
    </article>
    <aside class="note">
      <p>Constraints can let us choose resolution.</p>
      <p>Note that scaling and cropping aren't supported by browsers.</p>
    </aside>
</slide>

<slide>
  <hgroup>
  </hgroup>
    <article class="fill flexbox vcenter">
      <div style="margin: 0 0 1em 0; font-weight: bold">Select mic and camera</div>
      <div style="margin: 0 0 3em 0;"><a href="https://simpl.info/getusermedia/sources/" title="getUserMedia sources demo">simpl.info/getusermedia/sources
</a></div>
      <div style="font-size: 70%"><a href="https://play.google.com/store/apps/details?id=com.chrome.beta" title="Google Play: install Chrome Beta for Android">Install Chrome Beta for Android</a></div>
    </article>
    <aside class="note">
      <p>Constraints also let us choose media source.</p>
      <p>[Run, plug in camera, reload page, the show on Android Beta.]</p>
      <p>By the way, if you want to install Chrome Beta on your Android, you'll need to go via your browser, not the Google Play app.</p>
    </aside>
</slide>


<slide>
  <hgroup>
    <h2>Work underway to make this more user-focused</h2>
  </hgroup>
  <article>
    <ul>
      <li>User wants to choose "front-facing" or "rear-facing" camera, not a USB ID!</li>
      <li>Choose source: <a href="http://www.w3.org/TR/mediacapture-streams/#video-facing-mode-enum" title="W3C facing mode draft spec">spec</a></li>
      <li>Apply constraints dynamically from JavaScript: <a href="http://www.w3.org/TR/mediacapture-streams/#widl-MediaStreamTrack-applyConstraints-void-MediaTrackConstraints-constraints" title="W3C applyConstraints() draft spec">spec</a></li>
    </ul>
  </article>
  <aside class="note">
  <p></p>
    <p>Specs are being drafted to give more options for choosing devices,  resolutions and other constraints.</p>
    <p>Generic device choice, e.g. user-facing camera: not specific device ID.</p>
    <p>Selfie mode!</p>
    <p>With applyConstraints(): width, height, framerate, facingMode, etc.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>gUM screencapture!</h2>
  </hgroup>
  <article>
    <p style="margin: 0 0 3em 0;">Be sure to enable <a href="chrome://flags/#enable-usermedia-screen-capture">screen capture support in getUserMedia</a>!</p>
    <pre class="prettyprint" data-lang="javascript">
var constraints = {
  video: {
    mandatory: {
      chromeMediaSource: 'screen'
    }
  }
};

navigator.webkitGetUserMedia(constraints, gotStream);
</pre>
<!-- <a href="https://simpl.info/screencapture/" title="Screen capture–RTCPeerConnection demo">simpl.info/screencapture</a> -->
  </article>
  <aside class="note">
    <p>Tab capture is also available from Chrome apps.</p>
  </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div style='margin: 0 0 2em 0'><a href="https://html5-demos.appspot.com/static/getusermedia/screenshare.html" title="Screen sharing demo">Screen sharing</a></div>
      <div><a href="http://updates.html5rocks.com/2012/12/Screensharing-with-WebRTC" title="HTML5 Rocks update demoing tab capture">Tab capture: chrome.tabCapture</a></div>
    </article>
    <aside class="note">
    <p>Extremely useful for doing IT support for your extended family!</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>getUserMedia + Web Audio</h2>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
// Success callback when requesting audio input stream
function gotStream(stream) {
    var audioContext = new webkitAudioContext();

    // Create an AudioNode from the stream
    <b>var mediaStreamSource = audioContext.createMediaStreamSource(stream);</b>

    // Connect it to the destination or any other node for processing!
    mediaStreamSource.connect(audioContext.destination);
}

navigator.webkitGetUserMedia( <b>{audio:true}</b>, gotStream);
</pre>
  <p style='margin: 2em 0 0 0'>Make sure to enable Web Audio Input in about:flags!</p>

  </article>
  <aside class="note">
  <p>RTCPeerConnection will also accept Web Audio output.</p>
  </aside>
</slide>

 <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div style="margin: 0 0 1em 0; font-weight: bold">gUM + Web Audio + WebGL</div>
      <div><a href="http://www.webaudiodemos.appspot.com/input/index.html" title="Record audio">webaudiodemos.appspot.com/Vocoder</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>Media Stream Recording API</h2>
  </hgroup>
    <article>
    <ul>
      <li>Demo: <a href="http://simpl.info/mediarecorder" title="Media Stream Recording demo">simpl.info/mediarecorder</a></li>
      <li><a href="https://dvcs.w3.org/hg/dap/raw-file/default/media-stream-capture/MediaRecorder.html" title="W3C MediaRecorder draft spec">Spec</a></li>
      <li>Chrome <a href="https://groups.google.com/a/chromium.org/forum/?fromgroups=#!topic/blink-dev/2l_G_apqk30" title="blink-dev Media Stream Recording API Intent to Implement discussion">Intent to Implement</a></li>
      <li><a href="http://www.w3.org/TR/streams-api/" title="W3C Streams API draft spec">Streams API</a></li>
    </ul>
    </article>
    <aside class="note">
      <p>Needs Firefox!</p>
      <p>How does it work? A MediaRecorder is created which takes an audio stream from navigator.getUserMedia(). When a blob of recorded data becomes available (set to occur after two seconds) this is used to set the src of the audio element, using window.URL.createObjectURL().</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>Media Stream Image Capture API</h2>
  </hgroup>
    <article>
    <ul>
      <li><del>Demo</del></li>
      <li><a href="http://gmandyam.github.io/image-capture/" title="W3C Media Stream Image Capture draft spec">Spec</a></li>
      <li><code>getFrame()</code> creates an <code>ImageData</code> object available in <code>onframegrab</code></li>
      <li><code>takePhoto()</code> creates a Blob available in <code>onphoto</code></li>
    </ul>
    </article>
    <aside class="note">
      <p>How does it work? A MediaRecorder is created which takes an audio stream from navigator.getUserMedia(). When a blob of recorded data becomes available (set to occur after two seconds) this is used to set the src of the audio element, using window.URL.createObjectURL().</p>
    </aside>
</slide>


<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>RTCPeerConnection</h2>
    <h3>Audio and video communication between peers</h3>
  </hgroup>
  <aside class="note">
    <p>This is the API for audio and video communication, to create a connection between peers.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Communicate Media Streams</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
    <div>
      <img style="float: left; width: 27%;" src="images/caller.jpg" alt="WebRTC video chat: caller" />
      <div style="float: left; line-height: 2em; margin: 0 2em 0 2em; text-align: center;">
      →<br />
      getUserMedia<br />
      +<br />
      RTCPeerConnection<br />
      ←
      </div>
      <img  style="float: left; position: relative; top: 38px; width: 35%;" src="images/callee.jpg" alt="WebRTC video chat: callee" />
    </div>
  </article>
  <aside class="note">
    On the surface, the API is simple - get access to MediaStreams via getUserMedia, then plug them into a PeerConnection, and they will get sent to another WebRTC endpoint automatically. And when we receive media from the remote side, this goes into new MediaStreams that can be rendered in our web page.
  </aside>
</slide>

<!-- <slide class="nobackground">
  <hgroup>
    <h2>RTCPeerConnection does a lot</h2>
  </hgroup>
    <article>
  <ul>
    <li>Signal processing</li>
    <li>Codec handling</li>
    <li>Peer to peer communication</li>
    <li>Security</li>
    <li>Bandwidth management</li>
  </ul>
    <p>...</p>
    </article>
    <aside class="note">
    <p>Under the hood though, RTCPeerConnection is doing a lot - processing audio and video to remove noise, compressing the data using codecs, setting up the peer to peer pathway through NATs and firewalls, encrypting the data, ensuring we use the right amount of bandwidth...</p>
    </aside>
</slide>
 -->
<slide>
  <hgroup>
    <h2>WebRTC architecture</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/webrtcArchitecture.png" alt="WebRTC architecture diagram" />
  </article>
  <aside class="note">
    <p>Under the hood though, RTCPeerConnection is doing a lot - processing audio and video to remove noise, compressing the data using codecs, setting up the peer to peer pathway through NATs and firewalls, encrypting the data, ensuring we use the right amount of bandwidth...</p>
    <p>There's a lot of moving parts under the hood. Fortunately, with RTCPeerConnection, this is mostly abstracted away. You create a RTCPeerConnection, add your own MediaStreams to it, call a couple methods to set up the right parameters for the call, and off you go.</p>
  </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <div style="margin: 0 0 2em 0; font-weight: bold">RTCPeerConnection without signaling</div>
    <div class="big"><a href="http://www.simpl.info/pc" title="Simple one-page RTCPeerConnection example">simpl.info/pc</a></div>
  </article>
  <aside class="note">
    <p>If you want to understand how WebRTC works, it's good to learn about RTCPeerConnection first, before you try to get your head around signaling mechanisms.</p>
    <p>This 'single page' demo does just that.</p>
    <p>It's very verbose: take a look at the console.</p>
    <p>Also take a look at chrome://webrtc-internals.</p>
  </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div style="margin: 0 0 2em 0; font-weight: bold">The canonical, full-fat video chat app!</div>
      <div class='big'><a href="http://apprtc.appspot.com" title="Canonical RTCPeerConnection videochat example">apprtc.appspot.com</a></div>
    </article>
    <aside class="note">
    <p>This is the best place to start with a fully featured WebRTC app: RTCPeerConnection, with signaling provided by XHR and the Google Channel API.</p>
    </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>WebRTC infrastructure</h2>
    <h3>STUN, TURN and signaling</h3>
  </hgroup>
  <aside class="note">
    <p>Or, that's what the nice fluffy white cloud I showed you would make you think.First, let's take a detour...</p>
  </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div>Peer to peer &mdash; but we need servers  :^\</div>
    </article>
    <aside class="note">
      <p>You may be asking, what does WebRTC need servers for?</p>
      <p>Well, it's not really scalable to simply shout into the Internet, 'I want to exchange streaming data with my friend's computer! He's right over there!'.</p>
      <p>We need to negotiate that connection.</p>
    </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>Signaling - coordinating communication</h2>
  </hgroup>
  <article>
    <ul>
      <li>Need to cope with NATs and firewalls: STUN and TURN</li>
      <li>To do this, we exchange 'session description' objects:</li>
      <ul class="tight">
        <li>What media formats I support, what I want to send</li>
        <li>Network information for peer-to-peer setup</li>
      </ul>
      <li>Signaling *can* use any messaging mechanism or protocol</li>
    </ul>
  </article>
  <aside class="note">
    <p>Signaling is the process of coordinating communication. Just like making a phone call, where the phone system is responsible for making connections, traversing the network - The same is true for WebRTC. A message needs to get sent by each side indicating the parameters they want to use for the call. This is called a "session description", and it includes a bunch of details regarding codecs, encryption, network information, etc.</p>
    <p>The details aren't critical for most apps; they just need to exchange these messages in some way. The mechanism is up to the app - it can use WebSocket, XHR and Server-sent Events, whatever it wants to use, and whatever protocol - many apps will send these messages as JSON, although some apps may use the standard SIP or XMPP protocols.</p>

  </aside>
</slide>

<slide>
  <hgroup>
    <h2>JSEP architecture</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/jsep.png" alt="JSETP architecture diagram">
  </article>
    <aside class="note">
    <p>This is where the Javascript Session Establishment Protocol comes in to play.  The caller sends a session description to its signaling server in the cloud, which then forwards this on to the callee. Similarly, the callee then sends its own session description back through the cloud to the caller. Once each side has given the session descriptions to RTCPeerConnection, the peer-to-peer link is established and media can flow - and the server isn't part of that communication at all.</p>
  </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>RTCDataChannel</h2>
    <h3>Bidirectional communication of arbitrary data between peers</h3>
  </hgroup>
  <aside class="note">
    <p>The last API to talk about is RTCDataChannel.  </p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Communicate arbitrary data</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
  <div>

  <div style="float: left; width: 28%;">
    <img style="display: block; margin: 0 0 0.5em 0; position: relative; width: 100%;" src="images/jankInvadersScreenshot.jpg" alt="Game: caller" />
    <div style="background: #eee; font-family: 'Source Code Pro', 'Courier New', monospace; font-size: 0.5em; line-height: 1.2em; padding: 1em; white-space: pre;">onreceivemessage = handle(data);
...
var myData = [
  {
    id: "ship1";
    x: 24,
    y: 11,
    velocity: 7
  },
  ....
]
send(myData);
</div>
      </div>
      <div style="float: left; line-height: 2em; margin: 0 2em 0 2em; position: relative; text-align: center; top: 4em; width: 25%;">
      →<br />
      RTCDataChannel<br />
      +<br />
      RTCPeerConnection<br />
      ←
      </div>

      <div style="float: left; width: 28%;">
        <div style="background: #eee; font-family: 'Source Code Pro', 'Courier New', monospace; font-size: 0.5em; line-height: 1.2em; margin: 0 0 1em 0; padding: 1em; white-space: pre;">onreceivemessage = handle(data);
...
var myData = [
  {
    id: "ship7";
    x: 19,
    y: 4,
    velocity: 18
  },
  ....
]
send(myData);
</div>
        <img style="display: block; width: 100%;" src="images/jankInvadersScreenshotReversed.jpg" alt="Game: callee" />
      </div>

  </div>
  </article>
  <aside class="note">
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>RTCDataChannel</h2>
  </hgroup>
  <article>
    <ul>
      <li>Same API as WebSockets</li>
      <li>Ultra-low latency</li>
      <li>Optionally unreliable or reliable: <br />
      &mdash; Firefox and Chrome 31, Chrome 30 behind a flag</li>
      <li>Secure</li>
    </ul>
  </article>
    <aside class="note">
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>RTCDataChannel API</h2>
  </hgroup>
  <article>
<pre class="prettyprint" data-lang="javascript">
var pc = new webkitRTCPeerConnection(servers,
  {optional: [{RtpDataChannels: true}]});

pc.ondatachannel = function(event) {
  receiveChannel = event.channel;
  receiveChannel.onmessage = function(event){
    document.querySelector("div#receive").innerHTML = event.data;
  };
};

sendChannel = pc.createDataChannel("sendDataChannel", {reliable: false});

document.querySelector("button#send").onclick = function (){
  var data = document.querySelector("textarea#send").value;
  sendChannel.send(data);
};
</pre>
  </article>
    <aside class="note">

    <p>SCTP is now available in Chrome 30 (flagged) and 31 (no flag).</p>
  <p>- optional reliable transfer, e.g. for file sharing (though in fact this has been accomplished over RTP, the old protocol for RTCDataChannel, which in practice is actually pretty reliable)</p>
  <p>- binary data</p>
  <p>- built-in flow control (flow/congestion control is built into SCTP, and bandwidth is managed not capped).</p>
    </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div style="margin: 0 0 2em 0; font-weight: bold">RTCDataChannel without signaling</div>
      <div class="big"><a href="http://www.simpl.info/dc" title="Single page RTCDataChannel example">simpl.info/dc</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
      <div style="margin: 0 0 2em 0; font-weight: bold">File sharing with RTCDataChannel</div>
      <a class="big" href="http://www.sharefest.me/" title="Sharefest app">Sharefest</a>
  </article>
  <aside class="note">
  </aside>
</slide>

<!-- <slide class="nobackground">
  <article class="fill flexbox vcenter">
      <div style="margin: 0 0 2em 0; font-weight: bold">File sharing with RTCDataChannel</div>
      <a class="big" href="http://bit.ly/rtcdraw/" title="Sharefest app">bit.ly/rtcdraw</a>
  </article>
  <aside class="note">
  </aside>
</slide> -->

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <div style="margin: 0 0 2em 0; font-weight: bold">Peer to peer file distribution with RTCDataChannel</div>
    <a class="big" href="https://peercdn.com/" title="peerCDN">peerCDN</a>
  </article>
  <aside class="note">
  </aside>
</slide>



<slide>
  <hgroup>
    <h2>More Information</h2>
  </hgroup>
  <article>
  <ul class='tight'>
    <li>WebRTC and Web Audio resources list: <a href="http://bit.ly/webrtcwebaudio" title="WebRTC and Web Audio standards, documentation, tutorials, demos, samples and applications">bit.ly/webrtcwebaudio</a></li>
    <li><a href="http://www.youtube.com/watch?v=p2HzZkd2A40" title="Video of Google I/O 2013 WebRTC session on YouTube">Google I/O 2013 WebRTC presentation</a></li>
    <li>Justin Uberti: <a href="http://www.youtube.com/watch?v=E8C8ouiXHHk" title="Video of Google I/O 2012 presentation">Google I/O 2012 presentation video</a></li>
    <li>Cullen Jennings video: <a href="http://vimeo.com/47682405" title="IETF and W3C standardisation discussion">HTML5 WebRTC</a></li>
    <li>HTML5 Rocks:</li>
    <ul class='tight'>
      <li><a href="http://www.html5rocks.com/en/tutorials/getusermedia/intro/" title="HTML5 Rocks article about getUserMedia">Capturing audio and video in HTML5</a></li>
      <li><a href="http://www.html5rocks.com/en/tutorials/webrtc/basics/" title="HTML5 Rocks article about WebRTC">Getting Started With WebRTC</a></li>
      <li><a href="http://www.html5rocks.com/en/search?q=webrtc" title="HTML5 content tagged WebRTC">Updates</a></li>
    </ul>
    <li>...and a book: <a href="http://www.webrtcbook.com" title="WebRTC ebook download">webrtcbook.com</a></li>
  </ul>
  </article>
<aside class="note">
    <p></p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Contact Us</h2>
  </hgroup>
  <article>
  <ul>
    <li><a href="webrtc.org" title="WebRTC project website">webrtc.org</a></li>
    <li><a href="https://groups.google.com/forum/?fromgroups#!forum/discuss-webrtc" title="WebRTC discussion group">discuss-webrtc</a></li>
    <li><a href="https://plus.sandbox.google.com/113817074606039822053/posts" title="WebRTC on Google+">+webrtc</a></li>
      <li><a href="https://twitter.com/webrtc" title="WebRTC on Twitter">@webrtc</a></li>
      <li>  <a href="http://www.crbug.com/new" title="Report Chrome bugs and feature requests">crbug.com/new</a></li>
  </ul>
  </article>
<aside class="note">
    <p>webrtc.org has a blog, links to demos, documentation and links to code repositories</p>
    <p>...and follow Justin Uberti and Serge Lachapelle on Google+</p>
  </aside>
</slide>



<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Codecs for the modern Web</h2>
  </hgroup>
  <aside class="note">
    <p>Just a word about the work that's being done at Google on codecs.</p>
    <p>For WebRTC we need high quality open source codecs.</p>
    <p>That's one reason we've been hard at work on VP8 and VP9.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>VP8 and VP9</h2>
  </hgroup>
  <article>
  <ul>
    <li><a href="http://localhost/vp9/index.html" title="VP9/H.264 comparison">VP9 v H.264: Google I/O</a></li>
    <li><a href="http://wiki.webmproject.org/hardware/arm-socs">Systems with dedicated VP8 support</a></li>
  </ul>
  </article>
  <aside class="note">
    <p>So we test against x264, which is commonly regarded as the very best H.264 encoder</p>
    <p>we test against High Profile, using the very best settings.</p>
    <p>The conventional wisdom on HEVC is that it uses 50% of the bits of H.264. Our VP9 demo shows that we're using >50% fewer bits than H.264 as well.</p>
    <p>The data is obtained using the ffmpeg analysis tool</p>
    <p>Expect first chips supporting VP9 decode probably second half of 2014.</p>
  </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>Cross platform tools</h2>
  </hgroup>
  <article>
    <ul>
      <li><a href="http://www.ffmpeg.org/" title="FFmpeg site">FFmpeg</a></li>
      <li><a href="http://www.mirovideoconverter.com/" title="Miro video convertor">Miro</a></li>
      <li><a href="http://handbrake.fr/" title="Open source video transcoder">Handbrake</a> (uses FFmpeg)</li>
      <li><a href="http://www.videolan.org/vlc/index.html" title="Media player and transcoder">VLC</a></li>
      <li><a href="http://aws.amazon.com/elastictranscoder/" title="Amazon Elastic Transcoder site">Amazon Elastic Transcoder</a></li>
      <li><a href="http://zencoder.com/" title="Zencoder: transcoding in the cloud">Zencoder</a></li>
    </ul>
  </article>
  <aside class="note">
    <p>Tools for Mac, Windows and Linux</p>
    <p>Transcoding in the cloud</p>
  </aside>
</slide>





<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Chromecast</h2>
  </hgroup>
</slide>

<slide style="background-image: url(images/chromecast.jpg)" class="nobackground">
  <aside class="note">
    <p>Marvell SOC, hardware VP8 and H.264 decoding.</p>
    <p>512MB of RAM, 2GB of flash storage.</p>
    <p>Enables 'casting' from a web app to your television, or tab sharing via WebRTC.</p>
    <p>Integrated with your home wifi LAN.</p>
  </aside>
</slide>

<slide class="nobackground">
<!--   <hgroup>
    <h2>Chromecast</h2>
  </hgroup>
 -->  <article  class="fill flexbox vcenter"><a class="big" href="https://developers.google.com/cast/" title="Google Cast developer docs">Developer docs</a>
  </article>
  <aside class="note">
    <p>We are still in Preview and working hard to release the open SDK (V2).</p>
    <p>International launch soon.</p>
  </aside>
</slide>


<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>EME, MSE and DASH</h2>
  </hgroup>
</slide>

<slide>
  <hgroup>
    <h2>EME</h2>
    <h3>Encrypted Media Extensions</h3>
  </hgroup>
  <article>
    <ul>
      <li><a href="http://www.w3.org/TR/encrypted-media/" title="Encrypted Media Extensions W3C Working Draft">Spec</a></li>
      <li><a href="http://dash-mse-test.appspot.com" title="">YouTube demo</a></li>
      <li><a href="http://techblog.netflix.com/2013/04/html5-video-at-netflix.html" title="HTML5 Video at Netflix">Netflix on Chrome OS</a></li>
      <li><a href="http://downloads.webmproject.org/adaptive-encrypted-demo/adaptive/index.html" title="WebM encrypted+adaptive demo">WebM encrypted+adaptive demo</a></li>
      <li><a href="http://www.bbc.co.uk/rd/blog/2013/09/mpeg-dash-test-streams" title="BBC article about MPEG DASH">What is DASH?</a></li>
    </ul>
  </article>
  <aside class="note">
    <p>Broadcasters and distributors like the BBC and Netflix will not stream content without DRM.</p>
    <p>DRM until now has required plugins such as Flash and Silverlight.</p>
    <p>Plugins are being deprecated.</p>
    <p>EME is a JavaScript API that enables web applications to interact with DRM systems, in order to allow playback of encrypted media.</p>
    <p>These demos also use DASH, which allows streaming of media over HTTP, somewhat like Apple's HTTP Live Streaming.</p>
    <p>These examples use a JavaScript library</p>
  </aside>
</slide>


<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>MSE</h2>
    <h3>Media Source Extensions</h3>
  </hgroup>
  <aside class="note">
    <p></p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>JavaScript can generate streams for playback</h2>
  </hgroup>
  <article>
    <p><a href="w3.org/TR/media-source" title="MSE spec">Spec</a></p>
    <p><a href="updates.html5rocks.com/2011/11/Stream-video-using-the-MediaSource-API" title="Short MSE article on HTML5 Rocks">HTML5 Rocks Update</a></p>
    <p><a href="http://html5-demos.appspot.com/static/media-source.html" title="Media Source Extensions demo">Demo</a></p>
  </article>
  <aside class="note">
  </aside>
</slide>


<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>WebVTT, accessibility and timed metadata</h2>
  </hgroup>
</slide>


<slide>
  <hgroup>
    <h2>Captions and subtitles</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
    <p class="big"><a href="http://simpl.info/track" title="Track element demo">simpl.info/track</a></p>
  </article>
  <aside class="note">
    <p>The track element enables display of captions or subtitles from a VTT or SRT file.</p>
    <p>In-band WebVTT is also supported now by Chrome.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Deep linking, deep search</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
    <p class="quiteBig"><a href="http://samdutton.net/chromesearch" title="Chrome video search">samdutton.net/chromesearch</a></p>
  </article>
  <aside class="note">
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Synchronised metadata</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
    <p class="quiteBig"><a href="http://samdutton.net/mapTrack" title="Synchronised video, Google Map and Street View">samdutton.net/mapTrack</a></p>
  </article>
  <aside class="note">
  </aside>
</slide>




<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>...and finally</h2>
  </hgroup>
</slide>


<slide>
  <hgroup>
    <h2>Alpha transparency</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
    <p class="quiteBig"><a href="http://simpl.info/videoalpha" title="WebM alpha transparency demo">simpl.info/videoalpha</a></p>
  </article>
  <aside class="note">
    <p><a href="longtailvideo.com/html5" title="Source of stats: longtailvideo.com">85% video support</a>, audio similar, mobile and desktop</p>
    <p>Only need WebM (Chrome and Firefox) and MP4 (Safari and IE)</p>
    <p>This is just part of the great engineering that's going on</p>
  </aside>
</slide>













<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Tools</h2>
  </hgroup>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <a class="big" href="https://developers.google.com/speed/pagespeed/insights/" title="Page Speed Insights">Page Speed Insights</a>
  </article>
  <aside class="note">
  </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>APIs</h2>
  </hgroup>
  <article>
    <ul>
      <li><a href="http://localhost/simpl/navigationtiming/" title="Navigation Timing API demo">Navigation Timing</a></li>
      <li><a href="http://simpl.info/resourcetiming" title="Resource Timing API demo">Resource Timing</a></li>
      <li>Google Analytics: Behavior > Site Speed</li>
    </ul>
  </article>
  <aside class="note">
  <p>Want to know more? Check out the <li><a href="http://www.html5rocks.com/en/tutorials/webperformance/basics/" title="HTML5 Rocks article about Navigation Timing">HTML5 Rocks article</a></li>
</p>
  </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>Chrome Dev Tools</h2>
  </hgroup>
  <article>
    <ul>
      <li>chrome://inspect</li>
      <li>chrome://webrtc-internals</li>
      <li>Screencasting</li>
      <li>Workspaces</li>
    </ul>
  </article>
  <aside class="note">
    <p>You can access devices simply by going to chrome://inspect. No more ADB!</p>
    <p>Enter URL</p>
    <p>Experimental settings for screencast - then click icon.</p>
    <p>Two way control.</p>
    <p>Can check a lot about media APIs: check header for range requests, etc.</p>
  </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>Old friends</h2>
  </hgroup>
  <article>
    <ul>
      <li><a href="http://chromestatus.com" title="Status of APIS on Chrome">chromestatus.com</a></li>
      <li><a href="http://caniuse.com" title="API implementation stats">caniuse.com</a></li>
    </ul>
  </article>
  <aside class="note">
    <p>chromestatus.com has been updated</p>
  </aside>
</slide>





<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Best practice</h2>
  </hgroup>
</slide>

<slide class="nobackground">
  <article class="fill vcenter flexbox">
    <div class="quiteBig">7,000 different types of mobile device access Facebook every day.</div>
  </article>
 <footer class="source">Source: <a href="http://techcrunch.com/2012/08/03/vp-mike-schroepfer-7000-different-mobile-devices-access-facebook-every-day/">TechCrunch</a>, 3 August 2012</footer>
  <aside class="note">
    <p>This means 7,000 different sets of capabilities and constraints.</p>
    <p>This is from Facebook VP of Engineering, Mike Schroepfer</p>
    <p>And what it highlights is that we're moving to a bigger range of devices, in terms of power and performance.</p>
    <p>In other words, there's a bigger difference between a low-spec mobile phone and a high-spec tablet, than there is between a low-spec laptop and a high-spec desktop.</p>
  </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>Mobile is different!</h2>
  </hgroup>
  <article>
    <ul>
      <li>Consider quality and frame size</li>
      <li>&lt;video&gt; scripting doesn't work on iOS or Android</li>
      <li>Autoplay doesn't work on iOS or Android</li>
      <li>Preload: 25s on desktop, nothing on mobile</li>
      <li>Enable range requests</li>
      <li><a href="http://longtailvideo.com/html5" title="LongTail video article about HTML5 video support across platforms">The State of HTML5 video</a></li>
      <li><a href="http://stevesouders.com/tests/mediaevents.php" title="Steve Souders article about video preload buffer length">Steve Souders' preload test</a></li>
    </ul>
  </article>
  <aside class="note">
    <p>Can check if range requests are supported by going to Chrome Dev tools and looking for Accept-Ranges:bytes in the reponse headers.</p>

  </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>So what <strong>does</strong> work on mobile?</h2>
  </hgroup>
  <article>
    <ul>
      <li>Fallbacks: check out <a href="http://camendesign.co.uk/code/video_for_everybody" title="Video for Everybody video fallback using HTML only">Video for Everybody</a> (no JavaScript!)</li>
      <li>Poster element may be worthwhile</li>
      <li><a href="http://simpl.info/canplaytype" title="canPlayType() demo"><code>canPlayType()</code></a></li>
    </ul>
  </article>
  <aside class="note">
    <p>canPlayType() works on Android and iOS</p>
  </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>What about WebRTC?</h2>
  </hgroup>
  <article>
    <ul>
      <li>Impose limits via constraints or by editing SDP</li>
      <li>Make muting easy and obvious</li>
      <li>On desktop noone notices the permissions UI!</li>
    </ul>
  </article>
  <aside class="note">
    <p>canPlayType() works on Android and iOS</p>
  </aside>
</slide>







<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big"><a href="http://talky.io/webrtcintro" title="Video chat app">talky.io/webrtcintro</a></div>
    </article>
    <aside class="note">
    <p>WebRTC live!</p>
    </aside>
</slide>

<slide class="thank-you-slide segue nobackground">
  <aside class="gdbar right"><img src="images/google_developers_icon_128.png"></aside>
  <article class="flexbox vleft auto-fadein">
    <h2>&lt;Thank You!&gt;</h2>
      <p style="font-size:1.2em"><a href="http://mediaapis.appspot.com" style="color:inherit" title="These slides online">http://mediaapis.appspot.com</a></p>
  </article>
  <p class="auto-fadein" data-config-contact>
    <!-- populated from slide_config.json -->
  </p>
      <aside class="note">
    Once again, the link to the slides.
    </aside>
</slide>

<slide class="logoslide dark nobackground">
  <article class="flexbox vcenter">
    <span><img src="images/google_developers_logo_white.png"></span>
  </article>
</slide>

<slide class="backdrop"></slide>

</slides>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44413410-1', 'mediaapis.appspot.com');
  ga('send', 'pageview');

</script>

<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body>
</html>
